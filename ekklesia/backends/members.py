#!/usr/bin/env python
# coding: utf-8
#
# Member database
#
# Copyright (C) 2013-2017 by Thomas T. <ekklesia@heterarchy.net>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
# 
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# For more details see the file COPYING.

"""
This backend manages the relevant private data of members (including the departments) and
syncs them with the ID server and other backends.
It either uses an existing (external) or its own self-managed database (default).
For each member at least a UUID and email must be provided.
The fields in the DB are listed in member_import, and their names may be remapped (column_map).
The methods for accessing the fields can be overriden.
The settings are stored in members.ini

The full list of steps of the registration process:

In general the status may only be changed when the other side has acknowledged/mirrored it
0. init database or prepare external db
1. import member data, registered=None
 member must be imported before it can be transfered to invitations
 members are never deleted but set to deleted status (with status=deleted or --sync option)
 rows with missing uuids or duplicate uuids/emails are ignored
2. export member uuid[,email] for invitations
 optionally export only non-registered members using sync
3. import as invitations uuid[,email],
 creates: code,new,unsent,lastchange
 set status to deleted if the email is empty and member not registered
4. sync invitations:
4.1. download uuid,status for status=registered/failed/reset,
 additionally registering=new/new if not onlychanged
4.2. upload uuid,status,code
 if not quick: upload all new
 if uuid is unknown, upload status=deleted
 if download=new:
   status=new->upload/unsent - ready for sending
   invitation is not uploaded
 if download=failed/registered/reset:
   if status=uploaded->newstatus/unsent
   if status=newstatus: do nothing
   upload new status
 reset all failed/reset + sent invitations -> new
 reset is like failed, but no warning is sent to user
4.3. on idserver
 if status=new: create new invitation or update
 else: delete invitation
4.4. usually repeat download and update status (new->uploaded)
5. send invitations (for uploaded and unsent/retry) -> status=sent
 send registration/failure notification to registered/failed/reset -> sent
6. user registers with invitation/new (and secret if 2factor)
 invitation->registering, status->newmember
7. send email confirmation
8. email confirmed (delete confirmation, send notify registering -> 9.)
  or expired (status=deleted/invitation=failed, send notify failed -> 4.)
9. sync members
9.1. download uuid[,check_member][,check_email][,echo]
 for newmember (and check_member for 2factor/registering),
 and member/eligbile if not onlynew
 for quick sync ignore already registered members
9.2. upload uuid,status,verified,department[,check_member][,check_email][,gpslat,gpslng][,echo]
  gps if location enabled, echo or check_member/check_email if in download and enabled
 if check_member matches or no 2factor-> set registered,
 upload status, check_member status if 2factor
 export mail: uuid,email for all registered
 invitations: uuid,email for non-registered/non-deleted
 upload departments id,name,parent,depth
9.3. on idserver
 ignore unconfirmed-email members
 status: deleted->delete member, deactive login
  member/eligibile->newstatus, inv=registered and activate login
 deps: id,name,parent,depth - delete non-mentioned deps with id
 if activate was wrong->inv=failed,delete member
 send notify for failed/registered/reset status -> push invitations (4./5.)

The fields in the database and used in import/export/sync are:

field (format: member 1.0):
uuid    - unique member id (UUID max.36) as reference
memberno - unique member no (only if field is activated)
email   - email address
status  - member status: deleted, member, eligible
optional fields:
registered - UTC datetime when check_member was positiv for the first time
departments - department ids
parent  - parent department id (if department_spec is implicit)
verified - whether member is verified
location  - location of member
birthday  - birthday of member YYYY-MM-DD
extra for sync:
echo    - return in response (optional)
check_member - member to check, return 0/1 response if not empty (optional)
check_email - email to check, return 0/1 response if not empty (optional)

fields (format: department 1.0):
id      - numeric id (autogenerated) for sync
parent  - parent id
name    - string
depth   - child depth (optional)

import fields: all
export fields: all
export/sync email fields: uuid,email

Requirements: Python >=2.7, sqlalchemy, gnupg, requests, pygeocode
"""

from __future__ import print_function, absolute_import
from ekklesia.backends import (AbstractDatabase, api_defaults,
    FileMissingWarning, UnknownFieldsWarning, DeclEnum, EnumSymbol)
from ekklesia.mail import gpg_defaults, smtp_defaults
from ekklesia import FormattedWarning

members_spec="""
[members]
# the table name for members
member_table = string(default='members')
# columns to import from the table, optional: registered,verified,birthday,location
member_import = string_list(default=list('id','uuid','email','status','registered','departments'))
# whether import/export id as unique member_no
member_no = boolean(default=False)
# columns to sync, if empty member_sync = member_import
member_sync = string_list(default=list('uuid','status','verified','departments'))
# type of department field: number/name, implicit:reconstruct hierarchy from extra parent name
department_spec = option('implicit','number','name',default='name')
# the table name for departments
department_table = string(default='departments')
# columns to import from the table
department_import = string_list(default=list('id','parent','name','depth'))
# the table name for department member associations
depmembers_table = string(default='depmembers')
# columns to import from the table
depmembers_import = string_list(default=list('department_id','member_id'))
# field name for check_member, if empty disabled
check_member = string
# field name for check_member, if empty disabled
check_email = string
# sync: email+uuid export of registered members, independent of export --mail
export_emails = boolean(default=False)
# sync: email+uuid export of non-registered members
export_invite = boolean(default=True)
# required signature for import, receiver for export
io_key = string
# email of receiver for export --mail or sync
email_receiver = string
geolut_path = string(default='geolut.db')
broker = string
broker_exchange = string(default='id-backend')
broker_queue = string(default='id-members')
"""

class MStatusType(DeclEnum):
    deleted = EnumSymbol('deleted')
    member = EnumSymbol('member')
    eligible = EnumSymbol('eligible')

class MemberDatabase(AbstractDatabase):
    version = [1,0]

    def __init__(self, *args, **kwargs):
        super(MemberDatabase,self).__init__(*args, **kwargs)
        self.member_api = None
        self.smtpconfig = None

    def configure(self,config={},gpgconfig=gpg_defaults,apiconfig=api_defaults,
        smtpconfig=smtp_defaults):
        from ekklesia.backends import APIConfig, spec_defaults
        super(MemberDatabase,self).configure(config=config,gpgconfig=gpgconfig)
        api = api_defaults.copy()
        api.update(apiconfig)
        self.member_api = APIConfig(**api)
        self.smtpconfig = smtpconfig
        defaults = spec_defaults(members_spec)['members']
        for key in defaults.keys():
            setattr(self,key,config.get(key,defaults[key]))
        if not self.member_sync: self.member_sync = self.member_import
        assert self.department_spec != 'number' or 'id' in self.department_import, "id field required"
        return self

    def init_parser_import(self,subparsers,withfile=True):
        parser = super(MemberDatabase,self).init_parser_import(subparsers,withfile=False)
        parser.add_argument("input",nargs="+",help='input file(s) with members[,departments]')
        return parser

    def init_parser_export(self,subparsers):
        parser = super(MemberDatabase,self).init_parser_export(subparsers,withfile=False)
        parser.add_argument("output",nargs="+",help='output files for (members,departments) or emails')
        return parser

    def init_parser_sync(self,subparsers):
        parser = super(MemberDatabase,self).init_parser_sync(subparsers)
        parser.add_argument("-m","--mails",metavar='MAILS', help='output file for unregistered members')
        return parser

    def load_geolut(self):
        "load geo LUT from pickle file"
        import os, gzip, datetime
        from six.moves import cPickle
        geolut = {}
        fname = self.geolut_path
        if not os.path.exists(fname):
            self.warn(FileMissingWarning("GEOLUT %s doesn't exist", fname))
        else:
            with gzip.GzipFile(fname, 'rb') as f:
                geolut = cPickle.load(f)
                self.info('GEOLUT loaded')
        today = datetime.date.today()
        if not len(geolut) or ('lastquery' in geolut and geolut['lastquery']!=today):
            geolut['lastquery'] = today
            geolut['querylimit'] = 2500 #https://developers.google.com/maps/documentation/geocoding/#Limits
            geolut['address'] = {}
            self.info('query reset')
        self.geolut = geolut

    def save_geolut(self):
        import gzip
        from six.moves import cPickle
        with gzip.GzipFile(self.geolut_path, 'wb',compresslevel=6) as f:
            cPickle.dump(self.geolut, f, protocol=2)

    def gps_coord(self,address):
        "lookup GPS coordinates for address in LUT, if necessary from Google"
        from pygeocode import geocoder
        import datetime
        if not address: return None
        coord = None
        geolut = self.geolut
        try:
            coord = geolut['address'][address]
        except:
            today = datetime.date.today()
            if geolut['lastquery']==today and not geolut['querylimit']:
                return None
            else:
                geolut['lastquery'] = today
                geolut['querylimit'] = 2500
            try: result = geocoder.geocode_google(address)
            except geocoder.GeocoderRateLimitError:
                geolut['querylimit'] = 0
                return None
            except:
                result = False
            if result: coord = (result['lat'],result['lng'])
            else: coord = False
            geolut['address'][address] = coord
            geolut['querylimit'] -= 1
        return coord

    def get_location(self,member):
        "get the location field of a member"
        return member.location

    def set_location(self,member, location):
        "set the location field of a member"
        member.location = location

    def get_departments(self,member):
        "get the departments field of a member"
        if not self.department_table: return
        return member.departments

    def set_departments(self,member,departments):
        "set the department field of a member"
        if not self.department_table: return
        member.departments = departments

    def check_member_func(self,member,check):
        "default check function: compare with memberno"
        assert self.member_no, "memberno not supported"
        return member.id == int(check)

    def declare(self,reflect=True):
        from sqlalchemy import (Table, Column, Sequence, Enum, Integer, String,
                Boolean, Date, DateTime, ForeignKey, CheckConstraint)
        from sqlalchemy.orm import relationship, backref
        from ekklesia.data import init_object, repr_object

        def defdepth(ctx):
            "default depth: parent+1, without parent 0"
            parent = ctx.current_parameters['parent_id']
            return parent.depth+1 if parent else 0

        depid = self.department_table+'.id'

        class Department(self.Base):
            if not reflect:
                __tablename__ = self.department_table
                id = Column(Integer, Sequence('department_seq',optional=True), primary_key=True)
                #depno = Column(Integer, Sequence('depno_seq',optional=True), unique=True,index=True)
                parent_id = Column(Integer, ForeignKey(depid), nullable=True)
                name = Column(String(128))
                depth = Column(Integer, nullable=True,default=defdepth)
            else: # pragma: no cover
                __table__ = Table(self.department_table, self.Base.metadata, autoload=True,
                     extend_existing=True)
                if 'departments' in self.column_map:
                    __mapper_args__ = {'include_properties' : list(self.column_map['departments'].keys()) }
            children = relationship("Department",backref=backref('parent',remote_side="Department.id"))
            members = relationship(lambda: Member, secondary=self.depmembers_table, back_populates='departments', lazy="dynamic")
            # need trigger for: CheckConstraint('depth > parent.depth', name='depthcheck')

            def __init__(obj, **kwargs):
                super(self.Base,obj).__init__()
                obj.update(**kwargs)

            def update(obj, **kwargs):
                init_object(obj,**kwargs)

            def __repr__(obj):
                return repr_object(obj,list(self.department_columns)+['parent'])

        class Member(self.Base):
            if not reflect:
                __tablename__ = self.member_table
                id = Column(Integer, Sequence('member_seq',optional=True), primary_key=True) # =memberno if active
                uuid = Column(String(36), index=True, unique=True, nullable=False)
                email = Column(String(254), nullable=True, unique=True)
                status = Column(MStatusType.db_type(), nullable=False, default=MStatusType.member)
                if 'registered' in self.member_import:
                    registered = Column(DateTime, nullable=True)
                if 'verified' in self.member_import:
                    # null=unknown?->don't overwrite with sync
                    verified = Column(Boolean, nullable=True)
                if 'birthday' in self.member_import:
                    birthday = Column(Date, nullable=True)
                if 'location' in self.member_import:
                    location = Column(String(254), nullable=True)
            else: # pragma: no cover
                __table__ = Table(self.member_table, self.Base.metadata,
                    Column('status',MStatusType.db_type(), nullable=False, default=MStatusType.member),
                    autoload=True, extend_existing=True)
                if 'members' in self.column_map:
                    __mapper_args__ = {'include_properties' : list(self.column_map['members'].keys()) }
            departments = relationship(lambda: Department, secondary=self.depmembers_table, back_populates='members')

            def __init__(member, status=MStatusType.member, **kwargs):
                super(self.Base,member).__init__()
                kwargs['status'] = status
                member.update(**kwargs)

            def update(member, **kwargs):
                if 'location' in self.member_import and 'location' in kwargs:
                    self.set_location(member,kwargs['location'])
                    del kwargs['location']
                if not self.department_table and 'departments' in kwargs:
                    self.set_departments(member,kwargs['departments'])
                    del kwargs['departments']
                if 'uuid' in kwargs:
                    from uuid import uuid4
                    value = kwargs['uuid']
                    if not value: value = uuid4()
                    kwargs['uuid'] = str(value)
                init_object(member,**kwargs)

            def __repr__(member):
                replace={}
                if 'location' in self.member_import:
                    replace['location'] = self.get_location(member)
                if not self.department_table and 'departments' in self.member_columns:
                    replace['departments'] = self.get_departments(member)
                return repr_object(member,self.member_columns,replace)

        class DepartmentMember(self.Base):
            if not reflect:
                __tablename__ = self.depmembers_table
                department_id = Column(Integer, ForeignKey(depid), primary_key=True)
                member_id = Column(Integer, ForeignKey(self.member_table+'.id'), primary_key=True)
            else: # pragma: no cover
                __table__ = Table(self.depmembers_table, self.Base.metadata, autoload=True,
                    extend_existing=True)
                if 'depmembers' in self.column_map:
                    __mapper_args__ = {'include_properties' : list(self.column_map['depmembers'].keys()) }
            department = relationship("Department", backref=backref("depmembers", cascade="all, delete-orphan"))
            member = relationship("Member", backref=backref("depmembers", cascade="all, delete-orphan"))

        self.Department = Department
        self.Member = Member
        self.DepartmentMember = DepartmentMember

    def reflect_classes(self):
        from ekklesia.backends import reflect_class
        from ekklesia.data import frozendict
        import six
        self.member_columns, member_types = reflect_class(self.Member)
        self.department_columns, department_types = reflect_class(self.Department)
        deptype = int if self.department_spec == 'number' else six.text_type
        member_types['departments'] = (deptype,)
        department_types['parent'] = deptype
        self.member_types = frozendict(member_types)
        self.department_types = frozendict(department_types)

    def email_change(self,member,data):
        "called before email of member changes"

    def delete_member(self,member):
        "called before member is set to deleted status"

    def import_members(self,memberfile=None,depfile=None,decrypt=False,verify=False,
        dryrun=False,sync=False,allfields=False,format='csv'):
        """import data from memberfile, optionally depfile (if not implicit).
        allfields is used for restore and requires all columns.
        if sync, uuids not seen in input are set to status deleted.
        decrypt=with the default key, verify=check whether its signed with io_key.
        rows with missing uuids or duplicate uuids and emails are ignored.
        """
        from ekklesia.data import DataTable, init_object
        from sqlalchemy.orm import aliased
        session = self.session
        import_dep = self.department_spec != 'implicit' # extra Department data?
        Department = self.Department
        depprimary = 'id' if self.department_spec=='number' else 'name'
        dquery = session.query(Department)
        if verify: verify = self.io_key

        def get_department(id,create=False):
            # root dep: name,parent=None,depth=0
            # fwd-ref: name,parent=None,depth=None
            dep = dquery.filter_by(**id).first()
            if not dep and create and not dryrun:
                # create forward reference w/o depth, calculate it later
                dep = Department(parent=None,depth=None,**id)
                session.add(dep)
            return dep

        if depfile and import_dep and self.Department: # import separate department data
            columns = list(self.department_columns)+['parent']
            if allfields: reqcolumns = columns
            else: reqcolumns = ('name','parent')
            reader = DataTable(columns,coltypes=self.department_types,required=reqcolumns,
                dataformat='department',fileformat=format,version=self.version,gpg=self.gpg)
            count = 0
            reader.open(depfile,'r',encrypt=decrypt,sign=verify)
            columns = reader.get_columns()[0]
            seen = set() # detect duplicates
            for data in reader:
                if not 'depth' in columns: data['depth']=None
                # find existing parent by id, if not exist, create fwd-ref
                if not data['parent'] is None:
                    data['parent'] = get_department({depprimary:data['parent']},create=True)
                # find existing dep by id
                id = data[depprimary]
                if not id:
                    self.warn("identifier missing")
                    continue
                assert not id in seen, "department %s is duplicate" % id
                seen.add(id)
                dep = get_department({depprimary:id})
                if dep:
                    parent = data['parent']
                    while parent:
                        assert parent!=dep, "cycle detected for department %s" % id
                        parent = parent.parent
                # if not exist, create, set depth if parent.depth 
                depth = data['parent'].depth if data['parent'] else None
                if not depth is None: depth+=1
                if data['depth'] is None: data['depth'] = depth
                elif not depth is None: assert data['depth']>=depth, "invalid depth"
                count += 1
                if dryrun: continue
                if not dep: session.add(Department(**data))
                else: dep.update(**data)
            self.info('%i imported departments', count)
        elif not import_dep: # implicit
            dquery.update(dict(depth=None)) # reset all depths

        Member = self.Member
        columns = list(self.member_columns)+['departments']
        if allfields: reqcolumns = columns
        else:
            reqcolumns = ['uuid','email']
            if self.member_no: reqcolumns.append('id')
        if not import_dep and 'departments' in self.member_import and not 'parent' in columns:
            # implicit requires parent
            columns.append('parent')
            reqcolumns.append('parent')
        reader = DataTable(columns,coltypes=self.member_types,required=reqcolumns,
            dataformat='member',fileformat=format,version=self.version,gpg=self.gpg)
        count = 0
        reader.open(memberfile,'r',encrypt=decrypt,sign=verify)
        columns = reader.get_columns()[0]
        #primary either memberid or uuid
        #primary must exist for every member and be unique
        #primary+email must be unique
        if self.member_no:
            primary, primarykey = 'id', Member.id
        else:
            primary, primarykey = 'uuid', Member.uuid
        mquery = session.query(Member)
        seen, depseen = set(), set() # detect duplicates
        for data in reader:
            id = data[primary]
            if not id:
                self.warn("uuid missing")
                continue
            assert not id in seen, "member %s is duplicate" % id
            seen.add(id)
            if 'departments' in data:
                depids = data['departments']
                if import_dep: # all departments must exist
                    deps=set()
                    for depid in depids:
                        dep = get_department({depprimary:depid})
                        assert dep, "unknown department %s" % depid
                        deps.add(dep)
                    deps = list(deps)
                else: # implicit departments
                    assert len(depids)==1, "only single implicit department supported"
                    depid = depids[0]
                    # create departments from department and parent
                    # find existing parent by id, if not exist, create fwd-ref
                    parent = data['parent']
                    del data['parent']
                    if not parent is None:
                        parent = get_department({'name':parent},create=True)
                    # find existing dep by id
                    dep = get_department({'name':depid})
                    # if not exist, create, set depth if parent.depth
                    if dep:
                        sup = parent
                        while sup:
                            assert sup!=dep, "cycle detected for department %s" % depid
                            sup = sup.parent
                    depseen.add(depid)
                    if not dryrun:
                        if not dep:
                            dep = Department(name=depid,parent=parent,depth=None)
                            session.add(dep)
                        elif dep.parent != parent: # if parent changed and not seen, update
                            assert not depid in depseen, "department %s is duplicate" % depid
                            dep.update(parent=parent)
                    deps = [dep]
                data['departments'] = deps
            if 'email' in columns and not data['email']:
                data['email'] = None # make sure it's None
            # find existing member
            member = mquery.filter(primarykey==id).first()
            if data['email'] and not (member and member.email==data['email']):
                # email already used by other member?
                if session.query(primarykey,Member.email).filter_by(email=data['email']).first():
                    self.error("ignoring: duplicate email %s" % data['email'])
                    continue
            count += 1
            if dryrun: continue
            if member:
                if member.email != data['email']:
                    self.email_change(member,data)
                if data.get('status') == 'deleted':
                    self.delete_member(member)
                member.update(**data)
            else: session.add(Member(**data)) #new
        self.info('%i imported members', count)
        if sync: # deleted unseen members
            count = 0
            for member in session.query(Member).yield_per(1000):
                if member.status==MStatusType.deleted or member.uuid in seen: continue
                self.delete_member(member)
                member.status = MStatusType.deleted
                self.info("member %s deleted" % member.uuid)
                count += 1
            self.info('%i deleted members', count)
        # complete missing depths
        depalias = aliased(Department)
        fixdeps = session.query(Department.depth).filter_by(depth=None)
        if fixdeps.first(): # any departments with missing depths?
            fixdeps.filter_by(parent=None).update(dict(depth=0)) # set roots
            while fixdeps.first(): # fill from roots to leaves
                for sub in session.query(Department).join(depalias,Department.parent).\
                    filter(depalias.depth!=None).yield_per(1000):
                    sub.depth = sub.parent.depth+1
        if not dryrun: session.commit()

    def export_members(self,output,encrypt=None,sign=False,allfields=False,format='csv'):
        """export data, sorted by primary (uuid, or id with member_no), to output.
        allfields is used for backup and writes all columns.
        without allfields, data for the invitation DB is generated.
        output is [members,departments] if allfields, else just [members].
        encrypt=to io_key, sign=with default key.
        """
        from ekklesia.data import DataTable
        session = self.session
        Department, Member = self.Department, self.Member
        if allfields:
            columns = list(self.member_columns)+['departments']
            if not self.member_no: columns.remove('id')
            dataformat = 'member'
        else:
            columns = ('uuid','email')
            dataformat = 'invitation'
        writer = DataTable(columns,coltypes=self.member_types,gpg=self.gpg,
            dataformat=dataformat,fileformat=format,version=self.version)
        if encrypt: encrypt = [self.io_key]
        writer.open(output[0],'w',encrypt=encrypt,sign=sign)
        count = 0
        if allfields:
            query = session.query(Member).order_by(Member.id if self.member_no else Member.uuid)
        else:
            query = session.query(Member.uuid,Member.email,Member.registered).order_by(Member.uuid)
            if 'registered' in self.member_import:
                query = query.filter_by(registered=None) # don't export registered
        extra = {}
        for member in query.yield_per(1000):
            if allfields and member.departments: # FIXME: use get_department?
                if self.department_spec=='number':
                    depids = [department.id for department in member.departments]
                else:
                    depids = [department.name for department in member.departments]
                extra = dict(departments=depids)
            writer.write(member,extra)
            count += 1
        writer.close()
        self.info('%i exported members', count)
        if not allfields: return

        dwriter = DataTable(['id','name','parent','depth'],gpg=self.gpg,
            dataformat='department',fileformat=format,version=self.version)
        dwriter.open(output[1],'w',encrypt=encrypt,sign=sign)
        count = 0
        for dep in session.query(Department).order_by(Department.depth,Department.id).yield_per(1000):
            if dep.parent:
                extra = dict(parent=dep.parent.id if self.department_spec=='number' else dep.parent.name)
            else: extra = {}
            dwriter.write(dep,extra)
            count += 1
        dwriter.close()
        self.info('%i exported departments', count)

    def sync_members(self,download=True,upload=True,dryrun=False,quick=False,
            input=None,output=None,invitations=None,format='csv'):
        "sync members with ID server"
        from ekklesia.data import DataTable
        from ekklesia.backends import api_init
        from six.moves import cStringIO as StringIO
        import requests, json
        session = self.session
        Department, Member = self.Department, self.Member
        check_email = self.check_email
        check_member = self.check_member
        coltypes = self.member_types.copy()
        api = api_init(self.member_api._asdict())
        if download: # download registered uuids
            if input: input = json.load(input)
            else: # pragma: no cover
                url = self.member_api.url
                if quick: url+='?new=1'
                resp = api.get(url)
                if resp.status_code != requests.codes.ok:
                    if self.debugging: open('memberdown.html','w').write(resp.content)
                    assert False, 'cannot download used uuids'
                input = resp.json()
            if not input:
                self.warn("input is empty")
                return
            columns = ['uuid','echo']
            if check_member: columns.append(check_member)
            if check_email: columns.append(check_email)
            reader = DataTable(columns,required=['uuid'],coltypes=coltypes,gpg=self.gpg,
                dataformat='member',fileformat=self.member_api.format,version=self.version)
            sign = self.member_api.receiver if self.member_api.sign else False
            reader.open(input,'r',encrypt=self.member_api.encrypt,sign=sign)
        columns = list(self.member_sync)
        wcoltypes = dict(coltypes)
        if check_member: wcoltypes[check_member] = bool
        if check_email: wcoltypes[check_email] = bool
        wcoltypes['departments'] = (int,) # replace by list of ids
        if 'location' in self.member_sync:
            wcoltypes['gpslat'] = wcoltypes['gpslng'] = float
            columns += ['gpslat','gpslng']
        if download:
            rcolumns, unknown = reader.get_columns()
            if unknown: self.warn(UnknownFieldsWarning('ignoring unknown fields %s',unknown))
            if check_member and check_member in rcolumns: columns.append(check_member)
            if check_email and check_email in rcolumns: columns.append(check_email)
            if 'echo' in rcolumns: columns += ['echo']
        encrypt = [self.member_api.receiver] if self.member_api.encrypt else False
        encryptmail = [self.email_receiver] if self.member_api.encrypt else False
        writer = DataTable(columns,coltypes=wcoltypes,gpg=self.gpg,
            dataformat='member',fileformat=self.member_api.format,version=self.version)
        out = {}
        writer.open(out,'w',encrypt=encrypt,sign=self.member_api.sign)

        if not quick and self.export_emails:
            ewriter = DataTable(('uuid','email'),coltypes=coltypes,gpg=self.gpg,
                dataformat='member',fileformat=format,version=self.version)
            eout = output[2] if output else StringIO()
            ewriter.open(eout,'w',encrypt=encryptmail,sign=self.member_api.sign)

        def export(member,extra = {}):
            if 'location' in self.member_import:
                gps = self.gps_coord(self.get_location(member))
                if gps: extra['gpslat'],extra['gpslng'] = gps
            deps = self.get_departments(member)
            if self.department_spec=='number':
                deps = [dep.id for dep in deps]
            else:
                deps = [dep.name for dep in deps]
            if deps:
                extra['departments'] = deps
            writer.write(member,extra)
            if not quick and self.export_emails: ewriter.write(member)

        if invitations: registered = {} # dict of registered uuids

        mquery = session.query(Member)
        count = 0
        if download:
            from datetime import datetime
            seen = set()
            for data in reader:
                uuid = data['uuid']
                if not uuid:
                    self.warn("uuid missing")
                    continue
                if uuid in seen:
                    self.warn("member %s is duplicate" % uuid)
                    continue
                seen.add(uuid)
                member = mquery.filter_by(uuid=uuid).first()
                extra = {}
                if not member or (self.member_no and member.status == MStatusType.deleted):
                    self.warn("member %s is unknown" % uuid)
                    if check_member in columns and data[check_member]:
                        extra[check_member] = False
                    if check_email in columns and data[check_email]:
                        extra[check_email] = False
                    extra['departments'] = []
                    writer.write(Member(uuid=uuid,status=MStatusType.deleted),extra)
                    continue
                if check_email in columns and data[check_email]:
                    extra[check_email] = member.email == data[check_email]
                if check_member in columns:
                    if data[check_member]:
                        result = self.check_member_func(member,data[check_member])
                        if 'registered' in self.member_import:
                            if result and not member.registered:
                                member.registered = datetime.utcnow()
                    else:
                        if 'registered' in self.member_import and member.registered:
                            self.warn("member %s is already registered" % uuid)
                        result = None
                    extra[check_member] = result
                elif 'registered' in self.member_import and not member.registered:
                    member.registered = datetime.utcnow()
                if 'echo' in columns: extra['echo'] = data['echo']
                if not dryrun: export(member,extra)
                if invitations: registered[member.uuid] = True
                count += 1
        else:
            for member in mquery.yield_per(1000):
                if self.member_no and not member.memberno: continue # deleted
                if not dryrun: export(member)
                count += 1
        self.info('%i members exported', count)
        if not dryrun and 'registered' in self.member_import: session.commit()

        writer.close()
        if not quick and self.export_emails: ewriter.close()

        if not quick and invitations:
            iwriter = DataTable(('uuid','email'),coltypes=coltypes,gpg=self.gpg,
                dataformat='member',fileformat=format,version=self.version)
            # extra encrypt,sign
            iwriter.open(invitations,'w',encrypt=encryptmail,sign=self.member_api.sign)
            if self.member_no:
                query = session.query(Member.uuid,Member.email,Member.memberno).\
                    filter(Member.email!=None,Member.memberno!=0)
            else:
                query = session.query(Member.uuid,Member.email).filter(Member.email!=None)
            count = 0
            for member in query.yield_per(1000):
                if member.uuid in registered: continue # skip registered
                iwriter.write(member)
                count += 1
            iwriter.close()
            self.info('%i invitations exported', count)

        if not upload: return

        dwriter = DataTable(('id','name','parent','depth'),gpg=self.gpg,
            dataformat='department',fileformat=self.member_api.format,version=self.version)
        dout = {}
        dwriter.open(dout,'w',encrypt=encrypt,sign=self.member_api.sign)
        for dep in session.query(Department).order_by(Department.depth,Department.id).yield_per(1000):
            if dep.parent:
                extra = dict(parent=dep.parent.id)
                # if self.department_spec=='number' else dep.parent.name
            else: extra = {}
            dwriter.write(dep,extra)
        dwriter.close()

        if output:
            json.dump(out,output[0])
            json.dump(dout,output[1])
        elif not dryrun: # pragma: no cover
            resp = api.post(self.member_api.url,json=dict(members=out,departments=dout))
            if resp.status_code != requests.codes.ok:
                if self.debugging: open('memberup.html','w').write(resp.content)
                assert False, 'cannot upload data'

        if not self.export_emails or output or quick: return

        # pragma: no cover
        from ekklesia.mail import create_mail, smtp_init
        smtp = smtp_init(self.smtpconfig)
        smtp.open()
        self.info('sending email data')
        msg = create_mail(self.gpgconfig['sender'],self.email_receiver,'Email data',eout.getvalue())
        eout.close()
        msg, results = self.gpg.encrypt(msg,default_key=True,verify=True, inline=True)
        assert msg and results, 'error encrypting message'
        if not dryrun: smtp.send(msg)
        smtp.close()

    def process_update(self,msg,input=None,output=None):
        "process update valid messages with registering status for unregistered members"
        self.info('got update %s',msg)
        version = msg.get('version')
        if not (msg and msg.get('format')=='member' and len(version)==2):
            self.warn('invalid message')
            return False
        if version[0]!=1:
            self.warn('invalid message version %s', version)
            return False
        status, uuids = msg.get('status'), msg.get('uuid')
        if not (status and uuids):
            self.warn('invalid status %s or uuid %s', status, uuids)
            return False
        if status!='registering':
            self.debug('ignoring status %s', status)
            return False
        if 'registered' in self.member_import:
            if not isinstance(uuids,list): uuids = [uuids]
            query = self.session.query(self.Member)
            found = False
            for uuid in uuids:
                member = query.filter_by(uuid=uuid).first()
                if not member:
                    self.warn('uuid not found %s', uuid)
                elif member.registered:
                    self.warn('uuid already registered %s', uuid)
                else: found = True
            if not found: return False
        self.sync_members(self,quick=True,input=input,output=output)
        return True

    def run_import_members(self, args): # pragma: no cover
        from ekklesia.data import special_open
        if args.dryrun: self.info('simulating import')
        maxargs = 1 if self.department_spec=='implicit' else 2
        assert len(args.input) <= maxargs, "invalid number of input arguments"
        input = [special_open(file,'r') for file in args.input]
        if len(input)==1: input.append(None)
        self.import_members(memberfile=input[0],depfile=input[1],
                decrypt=args.decrypt,verify=args.verify,
                dryrun=args.dryrun,allfields=args.all,sync=args.sync)

    def run_export_members(self, args): # pragma: no cover
        from ekklesia.data import special_open
        assert len(args.output) == 2 if args.all else 1, "invalid number of output arguments"
        output = [special_open(file,'w') for file in args.output]
        assert not args.encrypt or self.gpg, "GnuPG not available"
        self.export_members(output,encrypt=args.encrypt,sign=args.sign,allfields=args.all)

    def run_push_members(self, args): # pragma: no cover
        if not args.daemon:
            import signal
            signal.signal(signal.SIGHUP, self.terminate)
            signal.signal(signal.SIGINT, self.terminate)
        assert not self.member_api.sign or self.gpgconfig['sender'], 'sender for signing missing'
        if args.dryrun: self.info('simulating push')
        if 'location' in self.member_import: self.load_geolut()
        self.push_sync(upload=args.upload,delay=args.wait,dryrun=args.dryrun)

    def run_sync_members(self, args): # pragma: no cover
        from ekklesia.data import special_open
        assert not self.member_api.sign or self.gpgconfig['sender'], 'sender for signing missing'
        if args.output:
            assert len(args.output) == 2+self.export_emails, "invalid number of output arguments"
        if args.dryrun: self.info('simulating sync')
        try:
            if 'location' in self.member_import: self.load_geolut()
            input = special_open(args.input,'r') if args.input else None
            if args.output: output = [special_open(file,'w') for file in args.output]
            else: output = None
            if self.export_invite and args.mails: invitations = special_open(args.mails,'w')
            else: invitations = None
            self.sync_members(download=args.download,upload=args.upload,quick=args.quick,
                input=input,output=output,dryrun=args.dryrun,invitations=invitations)
        finally:
            if 'location' in self.member_import: self.save_geolut()

    def load_config(self,cfgfile):
        from ekklesia.backends import api_spec
        from ekklesia.mail import gpg_spec, smtp_spec
        spec = members_spec+gpg_spec+smtp_spec+api_spec('member_api')
        config = self.get_configuration(spec,cfgfile,'members.ini')
        self.configure(config=config['members'],gpgconfig=config['gnupg'],
            apiconfig=config['member_api'],smtpconfig=config['smtp'])

    def run(self, args=None): # pragma: no cover
        from ekklesia.data import special_openwith, dummy_context
        from ekklesia.backends import session_context
        from sqlalchemy import create_engine
        import contextlib

        args, parser = self.init_run('members','synchronization of member databases',args)
        self.load_config(args.config)
        self.init_gnupg()
        if args.command=='push' and args.daemon:
            daemon = self.prepare_daemon(args.pid)
        else: daemon = dummy_context()
        with daemon, session_context(self):
            engine = create_engine(self.database,echo=False)
            if args.command == 'init':
                if args.drop:
                    self.info('dropping tables')
                    self.open_db(engine,mode='dropall' if args.all else 'drop')
                self.open_db(engine,mode='create')
                self.info('database intialized')
                if args.initial:
                    args.input = args.initial
                    args.decrypt = args.verify = args.all = args.sync = False
                    self.run_import_members(args)
                return
            self.open_db(engine,mode='open')
            if args.command == 'import':
                self.run_import_members(args)
            elif args.command == 'export':
                self.run_export_members(args)
            elif args.command == 'push':
                self.run_push_members(args)
            elif args.command == 'sync':
                self.run_sync_members(args)

def main_func(): # pragma: no cover
    MemberDatabase().run()

if __name__ == "__main__": main_func()
