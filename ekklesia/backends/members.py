#!/usr/bin/env python
# coding: utf-8
#
# Member database (sync)
#
# Copyright (C) 2013,2014 by entropy@heterarchy.net
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
# 
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
# For more details see the file COPYING.

"""
Backend syncing the departments and revelant private data of member with the ID server and other backends.
May be using data from an existing or its own database.
Minimum data: UUID, email
The fields in the DB are listed in member_import, and may have different names (column_map).
The methods for acessing the fields can be overriden. by default they access the field.

default: fully managed (own structure), optional fields for storage
 separate member + department tables
custom: existing db (mapping, department+parent etc), extra fields, overwrite access methods

fields (format: member 1.0):
uuid    - unique member id (UUID max.36) as reference
memberno - unique member no (optional)
email   - email address
status  - member status: deleted, member, eligible
verified - whether member is verified (optional)
registered - time when check_member was positiv for the first time (optional)
department - department id (optional)
parent  - parent department id (optional, if department_spec is implicit)
location  - location of member (optional)
birthday  - birthday of member YYYY-MM-DD (optional)
extra for sync:
echo    - return in response (optional)
check_member - member to check, return 0/1 response if not empty (optional)
check_email - email to check, return 0/1 response if not empty (optional)

fields (format: department 1.0):
id      - numeric id (autogenerated) for sync
parent  - parent id
name    - string
depth   - child depth (optional)

import fields: all
export fields: all
export/sync email fields: uuid,email

sync protocol:
relevant changes to member DB:
* user added -> new UUID, memberno, email?
* user deleted -> UUID or memberno NULL, or completely deleted (bad)
* depmt added
* depmt merged to upstream
relevant changes to upstream DB:
* user registered: UUID added for sync
* user deleted: UUID kept but not synced

1. download: only active, or registering UUIDs (newmember,inv=registering) are downloaded
 for registering UUIDs also include the activation passwort
 fields: uuid[,check_member][,check_email][,echo]
2. upload: replies to download (member,department),
 sync departments
 member fields: uuid,status,verified,department[,check_member][,check_email][,gpslat,gpslng][,echo]
  gps if location enabled, echo or check_member/email if in download and enabled
 if activation failed set invitation failed, if new member is deleted -> delete account
 update account status, if deleted deactivate

TODO: check changes to member, exception handling

Requirements: Python >=2.7, sqlalchemy, gnupg, requests, pygeocode
"""

from __future__ import print_function, absolute_import
from ekklesia.backends import (AbstractDatabase, APIConfig, spec_defaults, api_defaults,
    FileMissingWarning, UnknownFieldsWarning, DeclEnum, EnumSymbol)
from ekklesia.mail import gpg_defaults, smtp_defaults
from ekklesia import FormattedWarning

members_spec="""
[members]
member_table = string(default='members')
member_import = string_list(default=list('uuid','email','status','verified','department'))
# optional 'memberno','birthday','location'
# if empty member_sync = member_import
member_sync = string_list(default=list('uuid','status','verified','department'))
# type of department field: number/name, implicit:reconstruct hierarchy from extra parent name
department_spec = option('implicit','number','name',default='name')
department_table = string(default='departments')
department_import = string_list(default=list('id','parent','name','depth'))
check_member = string # field name for check_member, if empty disabled
check_email = string # field name for check_member, if empty disabled
# sync: email+uuid export, independent of export --mail
export_emails = boolean(default=False)
# sync: email+uuid export of non-registered members
export_invite = boolean(default=True)
# email of receiver for export --mail or sync
email_receiver = string
geolut_path = string(default='geolut.db')
"""

class StatusType(DeclEnum):
    deleted = EnumSymbol('deleted')
    member = EnumSymbol('member')
    eligible = EnumSymbol('eligible')

class MemberDatabase(AbstractDatabase):
    version = [1,0]

    def __init__(self,config={},gpgconfig=gpg_defaults,apiconfig=api_defaults,
        smtpconfig=smtp_defaults,logger=None):
        super(MemberDatabase,self).__init__(config,gpgconfig,logger)
        api = api_defaults.copy()
        api.update(apiconfig)
        self.member_api = APIConfig(**api)
        self.smtpconfig = smtpconfig
        assert self.version[0]<=1, 'invalid version'
        defaults = spec_defaults(members_spec)['members']
        for key in defaults.keys():
            setattr(self,key,config.get(key,defaults[key]))
        if not self.member_sync: self.member_sync = self.member_import
        assert self.department_spec != 'number' or 'id' in self.department_import, "id field required"

    def init_parser_import(self,subparsers):
        parser = subparsers.add_parser('import', help='import data')
        parser.add_argument("-a", "--all", action="store_true", default=False, help="require import of all fields")
        parser.add_argument("-d", "--decrypt", action="store_true", default=False, help="decrypt data")
        parser.add_argument("-v", "--verify", action="store_true", default=False, help="verify signature of data (required if signed)")
        parser.add_argument("-s", "--sync", action="store_true", default=False, help="keep only imported data")
        parser.add_argument("input",nargs="+",help='input file(s) with members[,departments]')
        return parser

    def init_parser_export(self,subparsers):
        parser = subparsers.add_parser('export', help='export data')
        parser.add_argument("-e", "--encrypt", action="store_true", default=False, help="encrypt data")
        parser.add_argument("-s", "--sign", action="store_true", default=False, help="sign data")
        parser.add_argument("-a", "--all", action="store_true", default=False, help="export all fields and departments, otherwise only mails")
        parser.add_argument("output",nargs="+",help='output files for (members,departments) or emails')
        return parser

    def init_parser_sync(self,subparsers):
        parser = super(MemberDatabase,self).init_parser_sync(subparsers)
        if self.export_invite:
            parser.add_argument("-m","--mails",metavar='MAILS',
                help='output file for unregistered members')
        return parser

    def load_geolut(self):
        import os, gzip, datetime
        from six.moves import cPickle
        geolut = {}
        fname = self.geolut_path
        if not os.path.exists(fname):
            self.warn(FileMissingWarning("GEOLUT %s doesn't exist", fname))
        else:
            with gzip.GzipFile(fname, 'rb') as f:
                geolut = cPickle.load(f)
                self.info('GEOLUT loaded')
        today = datetime.date.today()
        if not len(geolut) or ('lastquery' in geolut and geolut['lastquery']!=today):
            geolut['lastquery'] = today
            geolut['querylimit'] = 2500 #https://developers.google.com/maps/documentation/geocoding/#Limits
            geolut['address'] = {}
            self.info('query reset')
        self.geolut = geolut

    def save_geolut(self):
        import gzip
        from six.moves import cPickle
        with gzip.GzipFile(self.geolut_path, 'wb',compresslevel=6) as f:
            cPickle.dump(self.geolut, f, protocol=2)

    def gps_coord(self,address):
        from pygeocode import geocoder
        import datetime
        if not address: return None
        coord = None
        geolut = self.geolut
        try:
            coord = geolut['address'][address]
        except:
            today = datetime.date.today()
            if geolut['lastquery']==today and not geolut['querylimit']:
                return None
            else:
                geolut['lastquery'] = today
                geolut['querylimit'] = 2500
            try: result = geocoder.geocode_google(address)
            except geocoder.GeocoderRateLimitError:
                geolut['querylimit'] = 0
                return None
            except:
                result = False
            if result: coord = (result['lat'],result['lng'])
            else: coord = False
            geolut['address'][address] = coord
            geolut['querylimit'] -= 1
        return coord

    def get_location(self,member):
        return member.location

    def set_location(self,member, location):
        member.location = location

    def get_department(self,member):
        if not self.department_table: return
        return member.department

    def decode_department(self,member):
        if not self.department_table: return
        return member.department,member.parent,None,None # name,parent,id,depth

    def set_department(self,member,department):
        if not self.department_table: return
        member.department = department

    def check_member_func(self,member,check):
        "default check function"
        return member.memberno == int(check)

    def declare(self,reflect=True):
        from sqlalchemy import (Table, Column, Sequence, Enum, Integer, String,
                Boolean, Date, DateTime, ForeignKey, CheckConstraint)
        from sqlalchemy.orm import relationship, backref
        from ekklesia.data import init_object, repr_object

        def defdepth(ctx):
            parent = ctx.current_parameters['parent']
            return parent.depth+1 if parent else 0

        depid = self.department_table+'.id'

        class Department(self.Base):
            if not reflect:
                __tablename__ = self.department_table
                id = Column(Integer, Sequence('id_seq',optional=True), primary_key=True)
                #depno = Column(Integer, Sequence('depno_seq',optional=True), unique=True,index=True)
                parent_id = Column(Integer, ForeignKey(depid,name='parent_fk'), nullable=True)
                name = Column(String(128))
                depth = Column(Integer, nullable=True) #default=defdepth,
            else:
                __table__ = Table(self.department_table, self.Base.metadata)
                if 'departments' in self.column_map:
                    __mapper_args__ = {'include_properties' : list(self.column_map['departments'].keys()) }
            children = relationship("Department",backref=backref('parent',remote_side="Department.id"))
            members = relationship("Member",backref=backref('department',remote_side="Department.id") )
            CheckConstraint('depth > parent.depth', name='depthcheck')

            def __init__(obj, **kwargs):
                init_object(obj,**kwargs)
            def __repr__(obj):
                return repr_object(obj,self.department_columns+['parent'])

        class Member(self.Base):
            if not reflect:
                __tablename__ = self.member_table
                uuid = Column(String(36), unique=True, index=True, primary_key=True)
                email = Column(String(254), nullable=True, unique=True)
                status = Column(StatusType.db_type(), nullable=False, default=StatusType.member)
                department_id = Column(Integer, ForeignKey(depid,name='department_fk'), nullable=False)
                if 'verified' in self.member_import:
                    verified = Column(Boolean, nullable=True) # null=uknown?.q->dont overwrite with sync
                if 'memberno' in self.member_import:
                    memberno = Column(Integer, unique=True, nullable=True)
                if 'registered' in self.member_import:
                    registered = Column(DateTime, nullable=True)
                if 'birthday' in self.member_import:
                    birthday = Column(Date, nullable=True)
                if 'location' in self.member_import:
                    location = Column(String(254))
            else:
                __table__ = Table(self.member_table, self.Base.metadata)
                if 'members' in self.column_map:
                    __mapper_args__ = {'include_properties' : list(self.column_map['members'].keys()) }

            def __init__(member, **kwargs):
                if 'location' in self.member_import:
                    self.set_location(member,kwargs['location'])
                    del kwargs['location']
                if not self.department_table and 'department' in kwargs:
                    self.set_department(member,kwargs['department'])
                    del kwargs['department']
                if 'uuid' in kwargs:
                    from uuid import uuid4
                    value = kwargs['uuid']
                    if not value: value = uuid4()
                    kwargs['uuid'] = str(value)
                init_object(member,**kwargs)

            def __repr__(member):
                replace={}
                if 'location' in self.member_import:
                    replace['location'] = self.get_location(member)
                if not self.department_table and 'department' in self.member_columns:
                    replace['department'] = self.get_department(member)
                return repr_object(member,self.member_columns,replace)

        self.Department = Department
        self.Member = Member

    def reflect_classes(self):
        from ekklesia.backends import reflect_class
        self.member_columns, self.member_types = reflect_class(self.Member)
        self.department_columns, self.department_types = reflect_class(self.Department)
        deptype = int if self.department_spec == 'number' else str
        self.member_types['department'] = deptype
        self.department_types['parent'] = deptype

    def import_members(self,memberfile=None,depfile=None,decrypt=False,verify=False,
        dryrun=False,allfields=False,format='csv'):
        from ekklesia.data import DataTable
        from sqlalchemy.orm import aliased
        session = self.session
        import_dep = self.department_spec != 'implicit'
        Department = self.Department
        depprimary = 'id' if self.department_spec=='number' else 'name'
        dquery = session.query(Department)

        def get_department(id,create=False):
            # root dep: name,parent=None,depth=0
            # fwd-ref: name,parent=None,depth=None
            dep = dquery.filter_by(**id).first()
            if not dep and create and not dryrun:
                dep = Department(parent=None,depth=None,**id)
                session.add(dep)
            return dep

        if depfile and import_dep and self.Department:
            columns = self.department_columns + ['parent']
            if allfields: reqcolumns = columns
            else: reqcolumns = ('name','parent')
            reader = DataTable(columns,coltypes=self.department_types,required=reqcolumns,
                dataformat='department',fileformat=format,version=self.version,gpg=self.gpg)
            count = 0
            reader.open(depfile,'r',encrypt=decrypt,sign=verify)
            columns, tmp = reader.get_columns()
            seen = set()
            for data in reader:
                if not 'depth' in columns: data['depth']=None
                # find existing parent by id, if not exist, create fwd-ref
                if not data['parent'] is None:
                    data['parent'] = get_department({depprimary:data['parent']},create=True)
                # find existing dep by id
                id = data[depprimary]
                if not id:
                    self.warn("identifier missing")
                    continue
                assert not id in seen, "department %s is duplicate" % id
                seen.add(id)
                dep = get_department({depprimary:id})
                if dep:
                    parent = data['parent']
                    while parent:
                        assert parent!=dep, "cycle detected for department %s" % id
                        parent = parent.parent
                # if not exist, create, set depth if parent.depth 
                depth = data['parent'].depth if data['parent'] else None
                if not depth is None: depth+=1
                if data['depth'] is None: data['depth'] = depth
                elif not depth is None: assert data['depth']>=depth, "invalid depth"
                count += 1
                if dryrun: continue
                if not dep: session.add(Department(**data))
                else: dep.__init__(**data)
            self.info('%i imported departments', count)
        elif not import_dep:
            dquery.update(dict(depth=None)) # reset all depths

        Member = self.Member
        columns = self.member_columns + ['department']
        if allfields: reqcolumns = columns
        else: reqcolumns = ['uuid','email']
        if not import_dep and 'department' in self.member_import and not 'parent' in columns:
            columns.append('parent')
            reqcolumns.append('parent')
        reader = DataTable(columns,coltypes=self.member_types,required=reqcolumns,
            dataformat='member',fileformat=format,version=self.version,gpg=self.gpg)
        count = 0
        reader.open(memberfile,'r',encrypt=decrypt,sign=verify)
        columns, tmp = reader.get_columns()
        #primary either memberid or uuid
        #primary must exist for every member and be unique
        #primary+email must be unique
        if 'memberno' in columns: primary, primarykey = 'memberno', Member.memberno
        else: primary, primarykey = 'uuid', Member.uuid
        mquery = session.query(primarykey)
        seen, depseen = set(), set()
        for data in reader:
            id = data[primary]
            if not id:
                self.warn("uuid missing")
                continue
            assert not id in seen, "member %s is duplicate" % id
            seen.add(id)
            if 'department' in data:
                depid = data['department']
                if import_dep: # all departments must exist
                    dep = get_department({depprimary:depid})
                    assert dep, "unknown department %s" % depid
                else: # create departments from department and parent
                    # find existing parent by id, if not exist, create fwd-ref
                    parent = data['parent']
                    del data['parent']
                    if not parent is None:
                        parent = get_department({'name':parent},create=True)
                    # find existing dep by id
                    dep = get_department({'name':depid})
                    # if not exist, create, set depth if parent.depth
                    if dep:
                        sup = parent
                        while sup:
                            assert sup!=dep, "cycle detected for department %s" % depid
                            sup = sup.parent
                    depseen.add(depid)
                    if not dryrun:
                        if not dep:
                            dep = Department(name=depid,parent=parent,depth=None)
                            session.add(dep)
                        elif dep.parent != parent: # if parent changed and not seen, update
                            assert not depid in depseen, "department %s is duplicate" % depid
                            dep.__init__(parent=parent)
                data['department'] = dep
            if 'email' in columns and not data['email']: data['email']=None
            member = mquery.filter_by(**{primary:id}).first()
            if data['email']:
                email = session.query(primarykey,Member.email).\
                    filter_by(email=data['email']).first()
            else: email = None
            if email and (not member or getattr(email,primary) != getattr(member,primary)):
                self.error("ignoring: duplicate email %s" % data['email'])
                continue
            count += 1
            if dryrun: continue
            if member: member.__init__(**data)
            else: session.add(Member(**data)) #new
        self.info('%i imported members', count)
        # complete missing depths
        depalias = aliased(Department)
        fixdeps = session.query(Department.depth).filter_by(depth=None)
        if fixdeps.first():
            fixdeps.filter_by(parent=None).update(dict(depth=0)) # set roots
            while fixdeps.first():
                for sub in session.query(Department).join(depalias,Department.parent).\
                    filter(depalias.depth!=None):
                    sub.depth = sub.parent.depth+1
        if not dryrun: session.commit()

    def export_members(self,output,encrypt=None,sign=False,allfields=False,format='csv'):
        from ekklesia.data import DataTable
        session = self.session
        Department, Member = self.Department, self.Member
        if allfields: columns = self.member_columns+['department']
        else: columns = ('uuid','email')
        writer = DataTable(columns,coltypes=self.member_types,gpg=self.gpg,
            dataformat='member',fileformat=format,version=self.version)
        if encrypt: encrypt = [encrypt]
        writer.open(output[0],'w',encrypt=encrypt,sign=sign)
        count = 0
        if allfields:
            query = session.query(Member).order_by(Member.memberno if 'memberno' in columns else Member.uuid)
        else:
            query = session.query(Member.uuid,Member.email).filter(Member.email!=None).order_by(Member.uuid)
        extra = {}
        for member in query:
            if allfields and member.department:
                depid = member.department.id if self.department_spec=='number' else member.department.name
                extra = dict(department=depid)
            writer.write(member,extra)
            count += 1
        writer.close()
        self.info('%i exported members', count)
        if not allfields: return

        dwriter = DataTable(['id','name','parent','depth'],gpg=self.gpg,
            dataformat='department',fileformat=format,version=self.version)
        dwriter.open(output[1],'w',encrypt=encrypt,sign=sign)
        count = 0
        for dep in session.query(Department).order_by(Department.depth,Department.id):
            if dep.parent:
                extra = dict(parent=dep.parent.id if self.department_spec=='number' else dep.parent.name)
            else: extra = {}
            dwriter.write(dep,extra)
            count += 1
        dwriter.close()
        self.info('%i exported departments', count)

    def sync_members(self,download=True,upload=True,dryrun=False,
            input=None,output=None,invitations=None,format='csv'):
        # format for emails and invitations export
        from ekklesia.data import DataTable
        from ekklesia.backends import api_init
        from six.moves import cStringIO as StringIO
        import requests, datetime, json
        session = self.session
        Department, Member = self.Department, self.Member
        check_email = self.check_email
        check_member = self.check_member
        coltypes = self.member_types.copy()
        api = api_init(self.member_api._asdict())
        if download: # download registered uuids
            if input: input = json.load(input)
            else:
                resp = api.get(self.member_api.url)
                assert resp.status_code == requests.codes.ok, 'cannot download used uuids'
                input = resp.json()
            columns = ['uuid','echo']
            if check_member: columns.append(check_member)
            if check_email: columns.append(check_email)
            reader = DataTable(columns,required=['uuid'],coltypes=coltypes,gpg=self.gpg,
                dataformat='member',fileformat=self.member_api.format,version=self.version)
            reader.open(input,'r',encrypt=self.member_api.encrypt,sign=self.member_api.receiver)
        columns = list(self.member_sync)
        wcoltypes = dict(coltypes)
        if check_member: wcoltypes[check_member] = bool
        if check_email: wcoltypes[check_email] = bool
        wcoltypes['department'] = int # replace by ids
        if 'location' in self.member_sync:
            wcoltypes['gpslat'] = wcoltypes['gpslng'] = float
            columns += ['gpslat','gpslng']
        if download:
            rcolumns, unknown = reader.get_columns()
            if unknown: self.warn(UnknownFieldsWarning('ignoring unknown fields %s',unknown))
            if check_member and check_member in rcolumns: columns.append(check_member)
            if check_email and check_email in rcolumns: columns.append(check_email)
            if 'echo' in rcolumns: columns += ['echo']
        encrypt = [self.member_api.receiver] if self.member_api.encrypt else False
        encryptmail = [self.email_receiver] if self.member_api.encrypt else False
        writer = DataTable(columns,coltypes=wcoltypes,gpg=self.gpg,
            dataformat='member',fileformat=self.member_api.format,version=self.version)
        out = {}
        writer.open(out,'w',encrypt=encrypt,sign=self.member_api.sign)

        if self.export_emails:
            ewriter = DataTable(('uuid','email'),coltypes=coltypes,gpg=self.gpg,
                dataformat='member',fileformat=format,version=self.version)
            eout = output[2] if output else StringIO()
            ewriter.open(eout,'w',encrypt=encryptmail,sign=self.member_api.sign)

        def export(member,extra = {}):
            if 'location' in self.member_import:
                gps = self.gps_coord(self.get_location(member))
                if gps: extra['gpslat'],extra['gpslng'] = gps
            dep = self.get_department(member)
            if dep:
                extra['department'] = dep.id if self.department_spec=='number' else dep.name
            writer.write(member,extra)
            if self.export_emails: ewriter.write(member)

        if invitations: registered = {} # dict of registered uuids

        mquery = session.query(Member)
        count = 0
        check_memberno = 'memberno' in self.member_columns
        if download:
            seen = set()
            for data in reader:
                uuid = data['uuid']
                if not uuid:
                    self.warn("uuid missing")
                    continue
                if uuid in seen:
                    self.warn("member %s is duplicate" % uuid)
                    continue
                seen.add(uuid)
                member = mquery.filter_by(uuid=uuid).first()
                extra = {}
                if not member or (check_memberno and not member.memberno): # deleted
                    self.warn("member %s is unknown" % uuid)
                    if check_member in columns and data[check_member]:
                        extra[check_member] = False
                    if check_email in columns and data[check_email]:
                        extra[check_email] = False
                    writer.write(Member(uuid=uuid,status=StatusType.deleted),extra)
                    continue
                if check_email in columns and data[check_email]:
                    extra[check_email] = member.email == data[check_email]
                if check_member in columns:
                    if data[check_member]:
                        result = self.check_member_func(member,data[check_member])
                        if 'registered' in self.member_import:
                            if result and not member.registered:
                                member.registered = datetime.datetime.utcnow()
                    else: result = None
                    extra[check_member] = result
                if 'echo' in columns: extra['echo'] = data['echo']
                if not dryrun: export(member,extra)
                if invitations: registered[member.uuid] = True
                count += 1
        else:
            for member in mquery:
                if check_memberno and not member.memberno: continue # deleted
                if not dryrun: export(member)
                count += 1
        self.info('%i members exported', count)
        if not dryrun and 'registered' in self.member_import: session.commit()

        writer.close()
        if self.export_emails: ewriter.close()

        if invitations:
            iwriter = DataTable(('uuid','email'),coltypes=coltypes,gpg=self.gpg,
                dataformat='member',fileformat=format,version=self.version)
            # extra encrypt,sign
            iwriter.open(invitations,'w',encrypt=encryptmail,sign=self.member_api.sign)
            if check_memberno:
                query = session.query(Member.uuid,Member.email,Member.memberno).\
                    filter(Member.email!=None,Member.memberno!=0)
            else:
                query = session.query(Member.uuid,Member.email).filter(Member.email!=None)
            count = 0
            for member in query:
                if member.uuid in registered: continue # skip registered
                iwriter.write(member)
                count += 1
            iwriter.close()
            self.info('%i invitations exported', count)

        if not upload: return

        dwriter = DataTable(('id','name','parent','depth'),gpg=self.gpg,
            dataformat='department',fileformat=self.member_api.format,version=self.version)
        dout = {}
        dwriter.open(dout,'w',encrypt=encrypt,sign=self.member_api.sign)
        for dep in session.query(Department).order_by(Department.depth,Department.id):
            if dep.parent:
                extra = dict(parent=dep.parent.id if self.department_spec=='number' else dep.parent.name)
            else: extra = {}
            dwriter.write(dep,extra)
        dwriter.close()

        if output:
            json.dump(out,output[0])
            json.dump(dout,output[1])
        elif not dryrun:
            r = api.post(self.member_api.url,json=dict(members=out,departments=dout))
            assert r.status_code == requests.codes.ok, 'cannot upload data'

        if not self.export_emails or output: return

        from ekklesia.mail import create_mail, smtp_init
        smtp = smtp_init(self.smtpconfig)
        smtp.open()
        self.info('sending email data')
        msg = create_mail(self.gpgconfig['sender'],self.email_receiver,'Email data',eout.getvalue())
        eout.close()
        msg, results = self.gpg.encrypt(msg,default_key=True,verify=True, inline=True)
        assert msg and results, 'error encrypting message'
        if not dryrun: smtp.send(msg)
        smtp.close()

    def run(self, args=None): # pragma: no cover
        from ekklesia.data import special_openwith, special_open
        args, engine, parser = self.init_run('members','synchronization of member databases',args)
        try:
            if args.command == 'init':
                self.open_db(engine,mode='create')
                self.info('database intialized')
                if args.initial:
                    with special_openwith(args.initial, 'r') as f:
                        self.import_members(f,allfields=True)
                return
            elif args.command == 'drop':
                self.info('deleting database')
                self.open_db(engine,mode='drop')
                return
            self.open_db(engine,mode='open')
        finally:
            if self.session: self.session.close()
        try:
            if args.command == 'import':
                if args.dryrun: self.info('simulating import')
                maxargs = 1 if self.department_spec=='implicit' else 2
                assert len(args.input) <= maxargs, "invalid number of input arguments"
                input = [special_open(file,'r') for file in args.input]
                if len(input)==1: input.append(None)
                self.import_members(memberfile=input[0],depfile=input[1],
                        decrypt=args.decrypt,verify=args.verify,
                        dryrun=args.dryrun,allfields=args.all)
            elif args.command == 'export':
                assert len(args.output) == 2 if args.all else 1, "invalid number of output arguments"
                output = [special_open(file,'w') for file in args.output]
                if args.encrypt:
                    assert self.gpg, "GnuPG not available"
                    encrypt = self.email_receiver if args.all else self.gpgconfig['sender'] #self
                else: encrypt = None
                self.export_members(output,encrypt=encrypt,sign=args.sign,allfields=args.all)
            elif args.command == 'sync':
                assert not self.member_api.sign or self.gpgconfig['sender'], 'sender for signing missing'
                if args.output:
                    assert len(args.output) == 2+self.export_emails, "invalid number of output arguments"
                if args.dryrun: self.info('simulating sync')
                try:
                    if 'location' in self.member_import: self.load_geolut()
                    input = special_open(args.input,'r') if args.input else None
                    if args.output: output = [special_open(file,'w') for file in args.output]
                    else: output = None
                    if self.export_invite and args.mails: invitations = special_open(args.mails,'w')
                    else: invitations = None
                    self.sync_members(download=args.download,upload=args.upload,
                        input=input,output=output,dryrun=args.dryrun,invitations=invitations)
                finally:
                    if 'location' in self.member_import: self.save_geolut()
        except:
            self.exception('')
        finally:
            self.session.close()

def main_func(): # pragma: no cover
    from ekklesia.backends import api_spec
    from ekklesia.mail import gpg_spec, smtp_spec
    import os, configobj, validate

    spec = members_spec+gpg_spec+smtp_spec+api_spec
    config = configobj.ConfigObj('members.ini', configspec=spec.split('\n'),encoding='UTF8')
    config.validate(validate.Validator())
    if not config['gnupg']['home']:
        config['gnupg']['home'] = os.path.join(os.getenv('HOME'),'.gnupg')
    else:
        config['gnupg']['home'] = os.path.expanduser(config['gnupg']['home'])
    MemberDatabase(config=config['members'],gpgconfig=config['gnupg'],
        apiconfig=config['api'],smtpconfig=config['smtp']).run()

if __name__ == "__main__": main_func()
